{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from multipage_classifier.dataset import UCSFDataset, UCSFDataModule\n",
    "from multipage_classifier.preprocessor import ImageProcessor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"multipage_classifier\"\n",
    "DATASET=\"../dataset/ucsf-idl-resized/\"\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "IMAGE_SIZE  = (512, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SwinModel, SwinConfig\n",
    "\n",
    "config = SwinConfig(\n",
    "    image_size=IMAGE_SIZE,\n",
    "    depths=[2, 2, 14, 2],\n",
    "    window_size=8,\n",
    "    patch_size=8,\n",
    "    embed_dim=96,\n",
    "    num_heads=[4, 8, 16, 32],\n",
    "    num_classes=0\n",
    ")\n",
    "swin_encoder = SwinModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98304\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = swin_encoder.config.image_size\n",
    "\n",
    "patch_size = swin_encoder.config.patch_size\n",
    "patch_size_stage_4 = patch_size * 2 * 2 * 2\n",
    "patches_stage_4 = (img_w /  patch_size_stage_4 )* (img_h / patch_size_stage_4)\n",
    "\n",
    "emb_dim = swin_encoder.config.embed_dim\n",
    "emb_dim_stage_4 = emb_dim * 2 * 2 * 2\n",
    "\n",
    "encoder_output_size = int(patches_stage_4 * emb_dim_stage_4)\n",
    "print(encoder_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multipage_classifier.encoder import EncoderForEmbedding\n",
    "\n",
    "encoder = EncoderForEmbedding(swin_encoder, encoder_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multipage_classifier.preprocessor import ImageProcessor\n",
    "image_processor = ImageProcessor(img_size=IMAGE_SIZE)\n",
    "\n",
    "data_module = UCSFDataModule(\n",
    "    Path(DATASET),\n",
    "    prepare_function=image_processor.prepare_input,\n",
    "    split=[0.8, 0.2],\n",
    "    batch_size=8,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate\n",
    "from multipage_classifier.dataset import collate, val_collate\n",
    "dataset_path = Path(DATASET)\n",
    "\n",
    "labels = json.load(open(dataset_path / \"labels.json\"))\n",
    "\n",
    "#random.shuffle(labels)\n",
    "\n",
    "classes = []\n",
    "for l in labels:\n",
    "    if l[\"type\"] not in classes:\n",
    "        classes.append(l[\"type\"])\n",
    "\n",
    "train_dataset = UCSFDataset(\n",
    "            dataset_path, labels, classes, image_processor.prepare_input\n",
    "        )\n",
    "dl = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate,\n",
    ")\n",
    "\n",
    "collate([train_dataset[0], train_dataset[1]])[\"page_nr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:494: UserWarning: The flag `devices=[0, 1]` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | encoder | SwinModel     | 41.8 M\n",
      "1 | heads   | ModuleDict    | 393 K \n",
      "2 | weights | ParameterDict | 4     \n",
      "------------------------------------------\n",
      "42.2 M    Trainable params\n",
      "4         Non-trainable params\n",
      "42.2 M    Total params\n",
      "168.676   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 14 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jscheibe/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/59 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1020.00 MiB (GPU 0; 23.69 GiB total capacity; 5.33 GiB already allocated; 843.88 MiB free; 6.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m logger \u001b[39m=\u001b[39m TensorBoardLogger(\u001b[39m\"\u001b[39m\u001b[39mlightning_logs\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39mNAME)\n\u001b[1;32m     18\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m, devices\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m], logger\u001b[39m=\u001b[39mlogger, max_epochs\u001b[39m=\u001b[39mN_EPOCHS, gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(encoder, data_module)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:213\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    212\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    217\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     85\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\n\u001b[1;32m     86\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbatch_idx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(optimizers, kwargs)\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:202\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, optimizers: List[Tuple[\u001b[39mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[0;32m--> 202\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position])\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:249\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    241\u001b[0m         closure()\n\u001b[1;32m    243\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    251\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:370\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    362\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe NVIDIA/apex AMP implementation has been deprecated upstream. Consequently, its integration inside\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m PyTorch Lightning has been deprecated in v1.9.0 and will be removed in v2.0.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m return True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39musing_native_amp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprecision_plugin, MixedPrecisionPlugin)\n\u001b[0;32m--> 370\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    371\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    372\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    373\u001b[0m     batch_idx,\n\u001b[1;32m    374\u001b[0m     optimizer,\n\u001b[1;32m    375\u001b[0m     opt_idx,\n\u001b[1;32m    376\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    377\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[1;32m    378\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1355\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1742\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1664\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1665\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1672\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1673\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m \u001b[39m    each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \n\u001b[1;32m   1741\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1742\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:169\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:234\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(\n\u001b[1;32m    235\u001b[0m     optimizer, model\u001b[39m=\u001b[39;49mmodel, optimizer_idx\u001b[39m=\u001b[39;49mopt_idx, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:119\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/optimization.py:333\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    331\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    336\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m group[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:105\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     94\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     99\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:149\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 135\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:419\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m    A ``ClosureResult`` containing the training step output.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    422\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1494\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1496\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/multipage-classifier/multipage_classifier/encoder.py:95\u001b[0m, in \u001b[0;36mEncoderForEmbedding.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch: Any, batch_idx: \u001b[39mint\u001b[39m):\n\u001b[0;32m---> 95\u001b[0m     losses, metrics, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(batch)\n\u001b[1;32m     96\u001b[0m     metrics[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(losses\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m     97\u001b[0m     metrics\u001b[39m.\u001b[39mupdate({(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m k \u001b[39melse\u001b[39;00m k): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m losses\u001b[39m.\u001b[39mitems()})\n",
      "File \u001b[0;32m~/multipage-classifier/multipage_classifier/encoder.py:54\u001b[0m, in \u001b[0;36mEncoderForEmbedding.step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, batch: Any):\n\u001b[0;32m---> 54\u001b[0m     emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(batch)\n\u001b[1;32m     55\u001b[0m     bs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(emb)\n\u001b[1;32m     57\u001b[0m     preds: Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/multipage-classifier/multipage_classifier/encoder.py:49\u001b[0m, in \u001b[0;36mEncoderForEmbedding.forward\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     48\u001b[0m     model_input \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input_keys}\n\u001b[0;32m---> 49\u001b[0m     cls_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_input)[\u001b[39m\"\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m#[:, 0, :]  # [batch_size, seq_len, hidden_size]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m cls_embeddings\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:998\u001b[0m, in \u001b[0;36mSwinModel.forward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdepths))\n\u001b[1;32m    996\u001b[0m embedding_output, input_dimensions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(pixel_values, bool_masked_pos\u001b[39m=\u001b[39mbool_masked_pos)\n\u001b[0;32m--> 998\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    999\u001b[0m     embedding_output,\n\u001b[1;32m   1000\u001b[0m     input_dimensions,\n\u001b[1;32m   1001\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1002\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1003\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1004\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1005\u001b[0m )\n\u001b[1;32m   1007\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm(sequence_output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:829\u001b[0m, in \u001b[0;36mSwinEncoder.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001b[0m\n\u001b[1;32m    825\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    826\u001b[0m         create_custom_forward(layer_module), hidden_states, input_dimensions, layer_head_mask\n\u001b[1;32m    827\u001b[0m     )\n\u001b[1;32m    828\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    830\u001b[0m         hidden_states, input_dimensions, layer_head_mask, output_attentions, always_partition\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    833\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    834\u001b[0m hidden_states_before_downsampling \u001b[39m=\u001b[39m layer_outputs[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:747\u001b[0m, in \u001b[0;36mSwinStage.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39mfor\u001b[39;00m i, layer_module \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks):\n\u001b[1;32m    745\u001b[0m     layer_head_mask \u001b[39m=\u001b[39m head_mask[i] \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    748\u001b[0m         hidden_states, input_dimensions, layer_head_mask, output_attentions, always_partition\n\u001b[1;32m    749\u001b[0m     )\n\u001b[1;32m    751\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    753\u001b[0m hidden_states_before_downsampling \u001b[39m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:701\u001b[0m, in \u001b[0;36mSwinLayer.forward\u001b[0;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[1;32m    698\u001b[0m hidden_states \u001b[39m=\u001b[39m shortcut \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_path(attention_windows)\n\u001b[1;32m    700\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm_after(hidden_states)\n\u001b[0;32m--> 701\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(layer_output)\n\u001b[1;32m    702\u001b[0m layer_output \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(layer_output)\n\u001b[1;32m    704\u001b[0m layer_outputs \u001b[39m=\u001b[39m (layer_output, attention_outputs[\u001b[39m1\u001b[39m]) \u001b[39mif\u001b[39;00m output_attentions \u001b[39melse\u001b[39;00m (layer_output,)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/models/swin/modeling_swin.py:569\u001b[0m, in \u001b[0;36mSwinIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    568\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 569\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_act_fn(hidden_states)\n\u001b[1;32m    570\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/multipage-classifier-training-AUw5wBFA-py3.10/lib/python3.10/site-packages/transformers/activations.py:57\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1020.00 MiB (GPU 0; 23.69 GiB total capacity; 5.33 GiB already allocated; 843.88 MiB free; 6.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Configure checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=\"best-checkpoint-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "checkpoint_callback.CHECKPOINT_NAME_LAST= \"checkpoint-{epoch:02d}-{val_loss:.4f}\"\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=NAME)\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=[0,1], logger=logger, max_epochs=N_EPOCHS, gpus=1)\n",
    "\n",
    "trainer.fit(encoder, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "labels = json.load(open(Path(DATASET) / \"labels.json\"))\n",
    "\n",
    "for label in tqdm(labels):\n",
    "    img_folder = label[\"image_folder\"]\n",
    "    for i, file in enumerate(os.listdir(Path(DATASET) / img_folder)):\n",
    "\n",
    "        path =  Path(DATASET) / img_folder / file\n",
    "        x = image_processor.prepare_input(Image.open(path)),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipage-classifier-training-AUw5wBFA-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ac4961f1a54f42faafdec5556e4f4c3e1beb539dc12fb47f919b6f0d50a14ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
