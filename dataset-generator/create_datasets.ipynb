{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"IDL-less_5_pages\"\n",
    "BASE_PATH = \"../dataset/ucsf-idl-resized\"\n",
    "SAMPLE_FILE  = \"samples.json\"\n",
    "\n",
    "# Filters:\n",
    "allowed_types = [\"email\", \"letter\", \"agenda\", \"comments\", \"report\", \"conference proceedings\", \"article\", \"memo\", 'photograph']\n",
    "min_types = 1\n",
    "max_types = 1\n",
    "\n",
    "min_pages = 1\n",
    "max_pages = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = json.load(open( Path(BASE_PATH) / SAMPLE_FILE ))\n",
    "\n",
    "labels = []\n",
    "for sample in samples:\n",
    "    label = {}\n",
    "    label[\"id\"] = sample[\"id\"]\n",
    "\n",
    "    if \"img_path\" in sample:\n",
    "        label[\"image_folder\"] = sample[\"image_folder\"]\n",
    "    else:\n",
    "        label[\"image_folder\"] = str(Path(\"images\") / str(sample[\"id\"]))  \n",
    "    \n",
    "    # Filters \n",
    "    if min_pages and not int(sample[\"pages\"]) >= min_pages:\n",
    "        continue\n",
    "    if max_pages and not int(sample[\"pages\"]) <= max_pages:\n",
    "        continue\n",
    "    label[\"pages\"] = sample[\"pages\"]\n",
    "    \n",
    "    types = sample[\"type\"].replace(\",\", \"\").replace(\";\", \"\").split(\" \")\n",
    "    types = [types] if len(types)== 0 else types\n",
    "    types = [t for t in types if t in allowed_types]\n",
    "    if min_types and not len(types) >= min_types:\n",
    "        continue\n",
    "    if max_types and not len(types) <= max_types:\n",
    "        continue\n",
    "    label[\"type\"] = types[0] \n",
    "\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "ds = {\n",
    "    \"labels\": labels,\n",
    "    \"metadata\": {\n",
    "        \"path\": str(Path(BASE_PATH).resolve()),\n",
    "        \"sample_file\": SAMPLE_FILE,\n",
    "        \"filters\": {\n",
    "            \"allowed_types\": allowed_types,\n",
    "            \"min_types\": min_types,\n",
    "            \"max_types\": max_types,\n",
    "            \"min_pages\": min_pages,\n",
    "            \"max_pages\": max_pages,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# save labels  \n",
    "json.dump(ds, open(Path(BASE_PATH) / f\"{DATASET_NAME}.json\", \"w+\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipage-dataset-generator-QLKKCkDD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3de697fe09c272f9ca88e5add6e5396c07292e69985217c4da3c1439d0e83758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
